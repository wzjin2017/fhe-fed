{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a76d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117 0.14.1+cu117\n",
      "====================0=========================\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /root/.torch/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 169001437/169001437 [00:10<00:00, 16413513.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.torch/cifar-100-python.tar.gz to /root/.torch\n",
      "Running on cpu\n",
      "GT label is 84. \n",
      "Onehot label is 84.\n",
      "torch.Size([12, 3, 5, 5]) True\n",
      "torch.Size([12]) True\n",
      "torch.Size([12, 12, 5, 5]) True\n",
      "torch.Size([12]) True\n",
      "torch.Size([12, 12, 5, 5]) True\n",
      "torch.Size([12]) True\n",
      "torch.Size([12, 12, 5, 5]) True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "torch.manual_seed(50)\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "\n",
    "# for i in [[0,1,2],[1,2,3], [2,3,4], [3,4,5],[4,5,6],[5,6,7],[6,7,8],[7,8,9]]:\n",
    "for i in range(1):\n",
    "    print(f\"===================={i}=========================\")\n",
    "    interval = 10\n",
    "    class_num = 100\n",
    "    \n",
    "    dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
    "    tp = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    tt = transforms.ToPILImage()\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    print(\"Running on %s\" % device)\n",
    "\n",
    "    def label_to_onehot(target, num_classes=class_num):\n",
    "        target = torch.unsqueeze(target, 1)\n",
    "        onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "        onehot_target.scatter_(1, target, 1)\n",
    "        return onehot_target\n",
    "\n",
    "    def cross_entropy_for_onehot(pred, target):\n",
    "        return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))\n",
    "\n",
    "    def weights_init(m):\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "        \n",
    "    class LeNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LeNet, self).__init__()\n",
    "            act = nn.Sigmoid\n",
    "            self.body = nn.Sequential(\n",
    "                nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "                act(),\n",
    "                nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "                act(),\n",
    "                nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "                act(),\n",
    "                nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "                act(),\n",
    "            )\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(768, class_num)\n",
    "            )\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.body(x)\n",
    "            out = out.view(out.size(0), -1)\n",
    "            # print(out.size())\n",
    "            out = self.fc(out)\n",
    "            return out\n",
    "        \n",
    "    net = LeNet().to(device)\n",
    "        \n",
    "    net.apply(weights_init)\n",
    "    criterion = cross_entropy_for_onehot\n",
    "\n",
    "    ######### honest partipant #########\n",
    "    img_index = 25\n",
    "    gt_data = tp(dst[img_index][0]).to(device)\n",
    "    gt_data = gt_data.view(1, *gt_data.size())\n",
    "    gt_label = torch.Tensor([dst[img_index][1]]).long().to(device)\n",
    "    gt_label = gt_label.view(1, )\n",
    "    gt_onehot_label = label_to_onehot(gt_label, num_classes=class_num)\n",
    "\n",
    "    plt.imshow(tt(gt_data[0].cpu()))\n",
    "    plt.title(\"Ground truth image\")\n",
    "    print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    gt_data.requires_grad = True\n",
    "    gt_onehot_label.requires_grad = True\n",
    "    # compute original gradient \n",
    "    out = net(gt_data)\n",
    "    y = criterion(out, gt_onehot_label)\n",
    "\n",
    "    dy_dx = torch.autograd.grad(y, net.parameters(), create_graph=True)\n",
    "\n",
    "\n",
    "    #grads = []\n",
    "\n",
    "    sensitivity_each_element = []\n",
    "    #sensitivity_each_layer = []\n",
    "    for layer_grad in dy_dx:\n",
    "        \n",
    "        print(layer_grad.shape, layer_grad.requires_grad)\n",
    "        sensitivity_each_element_current_layer = torch.zeros_like(layer_grad.view(-1))\n",
    "        #grad_of_layer_grad_to_y = []\n",
    "        count = 0\n",
    "        for each_element_grad in layer_grad.view(-1):\n",
    "                each_element_grad_to_y = torch.autograd.grad(each_element_grad, gt_onehot_label, retain_graph=True)[0][:,gt_label]\n",
    "                sensitivity_each_element_current_layer[count] = each_element_grad_to_y\n",
    "                #grad_of_layer_grad_to_y.append(each_element_grad_to_y.numpy()) \n",
    "                count += 1\n",
    "                if count % 10000 == 0:\n",
    "                    print(count)\n",
    "\n",
    "        #grad_of_layer_grad_to_y = torch.tensor(np.array(grad_of_layer_grad_to_y))\n",
    "        #grads.append(grad_of_layer_grad_to_y)\n",
    "        #sensitivity_each_layer.append(calculate_sensitivity_vector_range(grad_of_layer_grad_to_y))\n",
    "        sensitivity_each_element.append(sensitivity_each_element_current_layer)\n",
    "\n",
    "    flat_sensitivity_each_element = flat_grad(sensitivity_each_element)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810cfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0488d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_mask(vector, p = 0.1):\n",
    "\n",
    "    top_k_indices = torch.topk(vector, int(len(vector) * p), largest = True).indices\n",
    "\n",
    "    Mask = torch.zeros(vector.shape) == 0\n",
    "    Mask[top_k_indices] = False\n",
    "    return Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(flat_sensitivity_each_element, 'flat_sensitivity_each_element.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "    flat_original_dy_dx = flat_grad(original_dy_dx) #flat gradients to a vector\n",
    "\n",
    "    mask = get_top_k_mask(flat_sensitivity_each_element.abs(), 0.4)\n",
    "    \n",
    "    new_mask = torch.ones(flat_original_dy_dx.shape)\n",
    "    new_mask[:len(mask)] = mask\n",
    "    mask = new_mask\n",
    "    \n",
    "    flat_original_dy_dx = flat_original_dy_dx * mask\n",
    "    \n",
    "    gt_data.requires_grad = False\n",
    "    gt_onehot_label.requires_grad = False\n",
    "\n",
    "    # generate dummy data and label\n",
    "    dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
    "    dummy_label = torch.randn(gt_onehot_label.size()).to(device).requires_grad_(True)\n",
    "\n",
    "    plt.imshow(tt(dummy_data[0].cpu()))\n",
    "    plt.title(\"Dummy data\")\n",
    "    print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "\n",
    "    from ctypes import sizeof\n",
    "    optimizer = torch.optim.LBFGS([dummy_data, dummy_label])\n",
    "\n",
    "    history = []\n",
    "    mses = []\n",
    "    losses = []\n",
    "    for iters in range(30*interval):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = net(dummy_data) \n",
    "            dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
    "            dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            flat_dummy_dy_dx = flat_grad(dummy_dy_dx)\n",
    "            \n",
    "            flat_dummy_dy_dx = flat_dummy_dy_dx * mask  #with mask\n",
    "\n",
    "            grad_diff = ((flat_dummy_dy_dx - flat_original_dy_dx) ** 2).sum()\n",
    "            \n",
    "            grad_diff.backward()\n",
    "            losses.append(grad_diff.item())\n",
    "            return grad_diff\n",
    "        \n",
    "        optimizer.step(closure)\n",
    "\n",
    "\n",
    "        gt_arr = np.array(gt_data.cpu())\n",
    "        dummy_arr = np.array(dummy_data.detach().clone()[0].cpu())\n",
    "        mse = ((gt_arr - dummy_arr) ** 2).mean()\n",
    "        mses.append(mse)\n",
    "\n",
    "\n",
    "        if iters % interval == 0: \n",
    "            print(f\"{iters}, mse={mses[iters]}, loss = {losses[iters]}\")\n",
    "        history.append(tt(dummy_data[0].cpu()))\n",
    "        \n",
    "\n",
    "    # print(f\"losses = {losses}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(30):\n",
    "        ite_num = i * interval + interval - 1 \n",
    "        plt.subplot(3, 10, i + 1)\n",
    "        plt.imshow(history[ite_num] )\n",
    "        plt.title(\"iter=%d\" % (ite_num+1))\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "    filename = 'CIFAR'+str(class_num)+'_'+ str(30*interval) + 'ite_' + str(protected_layers) +'.png'\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    best_mse=min(mses[0:interval * 30])\n",
    "    idx = mses.index(best_mse)\n",
    "    print(f\"idx = {idx}, len = {len(mses)}\")\n",
    "    plt.imshow(history[idx])\n",
    "    plt.title(f\"best recovered image: ite={idx}, losses={best_mse}\")\n",
    "    filename = 'single_mse_' + filename\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "    print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
